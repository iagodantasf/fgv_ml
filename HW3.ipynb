{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980bc892-6032-4936-94da-3bd3168c7b2c",
   "metadata": {},
   "source": [
    "# Lista prática III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0bb64c-85cc-4db3-b8c6-944e91f4cfb4",
   "metadata": {},
   "source": [
    "**Instruções gerais:** Sua submissão deve conter: \n",
    "1. Um \"ipynb\" com seu código e as soluções dos problemas\n",
    "2. Uma versão pdf do ipynp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b3d19d",
   "metadata": {},
   "source": [
    "## Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0f751",
   "metadata": {},
   "source": [
    "O pedaço de código abaixo carrega o banco de dados 'breast cancer' e adiciona uma coluna de bias. Além disse, ele o particiona em treino e teste.\n",
    "\n",
    "1. Implemente a estimativa de máximo a posteriori para um modelo de regressão logística com priori $\\mathcal{N}(0, c I)$ com $c=100$ usando esse banco de dados;\n",
    "2. Implemente a aproximação de Laplace para o mesmo modelo;\n",
    "3. Implemente uma aproximação variacional usando uma Gaussiana diagonal e o truque da reparametrização;\n",
    "4. Calcule a accuracy no teste para todas as opções acima --- no caso das 2 últimas, a prob predita é $\\int_\\theta p(y|x, \\theta) q(\\theta)$;\n",
    "5. Para cada uma das 3 técnicas, plote um gráfico com a distribuição das entropias para as predições corretas e erradas (separadamente), use a função kdeplot da biblioteca seaborn.\n",
    "6. Comente os resultados, incluindo uma comparação dos gráficos das entropias.\n",
    "\n",
    "Explique sua implementação também! \n",
    "\n",
    "Para (potencialmente) facilitar sua vida: use PyTorch, Adam como otimizador (é uma variação SGD) com lr=0.001, use o banco de treino inteiro ao invés de minibatchces, use binary_cross_entropy_with_logits para implementar a -log verossimilhança, use torch.autograd.functional para calcular a Hessiana. Você pode usar as bibliotecas importadas na primeira célula a vontade. Verifique a documentação de binary_cross_entropy_with_logits para garantir que a sua priori está implementada corretamente, preservando as proporções devidas. Use 10000 amostras das aproximações para calcular suas predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data =  load_breast_cancer()\n",
    "N = len(data.data)\n",
    "Ntrain = int(np.ceil(N*0.6))\n",
    "perm = np.random.permutation(len(data.data))\n",
    "X = torch.tensor(data.data).float()\n",
    "X = torch.cat((X, torch.ones((X.shape[0], 1))), axis=1) \n",
    "y = torch.tensor(data.target).float()\n",
    "\n",
    "Xtrain, ytrain = X[perm[:Ntrain]], y[perm[:Ntrain]]\n",
    "Xtest, ytest = X[perm[Ntrain:]], y[perm[Ntrain:]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
